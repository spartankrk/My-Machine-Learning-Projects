{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment variables\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"]=\"notebook --no-browser\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecommerce Churn Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the assignment is to build a model that predicts whether a person purchases an item after it has been added to the cart or not. Being a classification problem, you are expected to use your understanding of all the three models covered till now. You must select the most robust model and provide a solution that predicts the churn in the most suitable manner. \n",
    "\n",
    "For this assignment, you are provided the data associated with an e-commerce company for the month of October 2019. Your task is to first analyse the data, and then perform multiple steps towards the model building process.\n",
    "\n",
    "The broad tasks are:\n",
    "- Data Exploration\n",
    "- Feature Engineering\n",
    "- Model Selection\n",
    "- Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset stores the information of a customer session on the e-commerce platform. It records the activity and the associated parameters with it.\n",
    "\n",
    "- **event_time**: Date and time when user accesses the platform\n",
    "- **event_type**: Action performed by the customer\n",
    "            - View\n",
    "            - Cart\n",
    "            - Purchase\n",
    "            - Remove from cart\n",
    "- **product_id**: Unique number to identify the product in the event\n",
    "- **category_id**: Unique number to identify the category of the product\n",
    "- **category_code**: Stores primary and secondary categories of the product\n",
    "- **brand**: Brand associated with the product\n",
    "- **price**: Price of the product\n",
    "- **user_id**: Unique ID for a customer\n",
    "- **user_session**: Session ID for a user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset provided is 5 GBs in size. Therefore, it is expected that you increase the driver memory to a greater number. You can refer to notebook 1 for the steps involved here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import countDistinct ,col, avg, mean, isnan, when, count, col, to_timestamp\n",
    "from pyspark.sql.types import IntegerType\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-63-36.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4316b06d10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialising the session with 14 GB driver memory\n",
    "MAX_MEMORY = \"14G\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"demo\") \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the clean data\n",
    "df_clean = spark.read.csv('/home/ec2-user/df_updated2', header= False, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+-----------+-----------+---+---+---+----+---+----+------+----+----+\n",
      "| _c0|_c1|_c2|        _c3|        _c4|_c5|_c6|_c7| _c8|_c9|_c10|  _c11|_c12|_c13|\n",
      "+----+---+---+-----------+-----------+---+---+---+----+---+----+------+----+----+\n",
      "|view|540|  6|electronics| smartphone| 35|  1| 35|null| 35| 3.0|huawei|   0|   0|\n",
      "|view|114|  5| appliances|environment|  1|  1|  1|null|  4| 0.0|others|   0|   0|\n",
      "|view| 39|  3|electronics|     clocks|  2|  2|  2|null|  2| 3.0| casio|   0|   0|\n",
      "|view|167|  6|electronics|      audio|  2|  2|  2|null| 14| 2.0|others|   0|   0|\n",
      "|view|161|  6|electronics|      audio| 12|  1|  1|null|121| 2.0| apple|   0|   0|\n",
      "+----+---+---+-----------+-----------+---+---+---+----+---+----+------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column names\n",
    "df_clean = df_clean.select(col(\"_c0\").alias(\"event_type\"), col(\"_c1\").alias(\"price\"), col(\"_c2\").alias(\"day_of_week\"), col(\"_c3\").alias(\"category1\"), col(\"_c4\").alias(\"category2\"), col(\"_c5\").alias(\"activity_countval\"), col(\"_c6\").alias(\"product_view_counts\"), col(\"_c7\").alias(\"category2_view_counts\"), col(\"_c8\").alias(\"average_shopping_expense\"), col(\"_c9\").alias(\"session_counts\"), col(\"_c10\").alias(\"binnedhour\"), col(\"_c11\").alias(\"brand_new\"), col(\"_c12\").alias(\"is_purchased\"), col(\"_c13\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "|event_type|price|day_of_week|  category1|  category2|activity_countval|product_view_counts|category2_view_counts|average_shopping_expense|session_counts|binnedhour|brand_new|is_purchased|label|\n",
      "+----------+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "|      view|  540|          6|electronics| smartphone|               35|                  1|                   35|                    null|            35|       3.0|   huawei|           0|    0|\n",
      "|      view|  114|          5| appliances|environment|                1|                  1|                    1|                    null|             4|       0.0|   others|           0|    0|\n",
      "|      view|   39|          3|electronics|     clocks|                2|                  2|                    2|                    null|             2|       3.0|    casio|           0|    0|\n",
      "|      view|  167|          6|electronics|      audio|                2|                  2|                    2|                    null|            14|       2.0|   others|           0|    0|\n",
      "|      view|  161|          6|electronics|      audio|               12|                  1|                    1|                    null|           121|       2.0|    apple|           0|    0|\n",
      "+----------+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15874983"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spark-sklearn in ./.local/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.18.1 in ./.local/lib/python3.7/site-packages (from spark-sklearn) (0.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Model Selection\n",
    "3 models for classification:\t\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional steps for Decision Trees, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df_clean.withColumn(\"is_purchased\",df_clean[\"is_purchased\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- category1: string (nullable = true)\n",
      " |-- category2: string (nullable = true)\n",
      " |-- activity_countval: integer (nullable = true)\n",
      " |-- product_view_counts: integer (nullable = true)\n",
      " |-- category2_view_counts: integer (nullable = true)\n",
      " |-- average_shopping_expense: double (nullable = true)\n",
      " |-- session_counts: integer (nullable = true)\n",
      " |-- binnedhour: double (nullable = true)\n",
      " |-- brand_new: string (nullable = true)\n",
      " |-- is_purchased: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Transformation (Code will be same; check for the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+---------+---------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "|event_type|price|day_of_week|category1|category2|activity_countval|product_view_counts|category2_view_counts|average_shopping_expense|session_counts|binnedhour|brand_new|is_purchased|label|\n",
      "+----------+-----+-----------+---------+---------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "|         0|    0|          0|        0|        0|                0|                  0|                    0|                       0|             0|         0|        0|           0|    0|\n",
      "+----------+-----+-----------+---------+---------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if only the required columns are present to build the model\n",
    "# If not, drop the redundant columns\n",
    "from pyspark.sql.functions import when, count, col, isnull, isnan\n",
    "df_clean.select([count(when(isnan(c), c)).alias(c) for c in df_clean.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xverse in ./.local/lib/python3.7/site-packages (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.11.3 in ./.local/lib/python3.7/site-packages (from xverse) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in ./.local/lib/python3.7/site-packages (from xverse) (0.19.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.3 in ./.local/lib/python3.7/site-packages (from xverse) (3.4.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in ./.local/lib/python3.7/site-packages (from xverse) (1.6.3)\n",
      "Requirement already satisfied: pandas>=0.21.1 in ./.local/lib/python3.7/site-packages (from xverse) (1.1.2)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in ./.local/lib/python3.7/site-packages (from xverse) (0.12.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.7/site-packages (from matplotlib>=3.0.3->xverse) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.7/site-packages (from matplotlib>=3.0.3->xverse) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.local/lib/python3.7/site-packages (from matplotlib>=3.0.3->xverse) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.local/lib/python3.7/site-packages (from matplotlib>=3.0.3->xverse) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.local/lib/python3.7/site-packages (from matplotlib>=3.0.3->xverse) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./.local/lib/python3.7/site-packages (from pandas>=0.21.1->xverse) (2020.1)\n",
      "Requirement already satisfied: patsy>=0.5 in ./.local/lib/python3.7/site-packages (from statsmodels>=0.6.1->xverse) (0.5.1)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.0.3->xverse) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_type',\n",
       " 'price',\n",
       " 'day_of_week',\n",
       " 'category1',\n",
       " 'category2',\n",
       " 'activity_countval',\n",
       " 'product_view_counts',\n",
       " 'category2_view_counts',\n",
       " 'average_shopping_expense',\n",
       " 'session_counts',\n",
       " 'binnedhour',\n",
       " 'brand_new',\n",
       " 'is_purchased',\n",
       " 'label']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df_clean.drop('event_type', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorising the attributes into its type - Continuous and Categorical\n",
    "# Storing the categorical and continuous columns in different lists\n",
    "all_categorical_features = ['day_of_week', 'category1', 'category2', 'binnedhour', 'brand_new']\n",
    "all_continuous_features = ['price', 'activity_countval', 'product_view_counts', 'category2_view_counts', 'session_counts', 'average_shopping_expense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the variable 'stages' to store every step for building a pipeline\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries for data transormation\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a function for encoding all the categorical variables\n",
    "for categoricalCol in all_categorical_features:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index').setHandleInvalid(\"keep\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector assembler to combine all the features\n",
    "assemblerInputs = [c + \"classVec\" for c in all_categorical_features] + all_continuous_features\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\").setHandleInvalid(\"keep\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for the tasks\n",
    "# Loading all the steps in a pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the dataframe df\n",
    "# Fitting the steps on the dataFrame\n",
    "pipelineModel = pipeline.fit(df_clean)\n",
    "df_clean = pipelineModel.transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- price: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- category1: string (nullable = true)\n",
      " |-- category2: string (nullable = true)\n",
      " |-- activity_countval: integer (nullable = true)\n",
      " |-- product_view_counts: integer (nullable = true)\n",
      " |-- category2_view_counts: integer (nullable = true)\n",
      " |-- average_shopping_expense: double (nullable = true)\n",
      " |-- session_counts: integer (nullable = true)\n",
      " |-- binnedhour: double (nullable = true)\n",
      " |-- brand_new: string (nullable = true)\n",
      " |-- is_purchased: integer (nullable = true)\n",
      " |-- day_of_weekIndex: double (nullable = false)\n",
      " |-- day_of_weekclassVec: vector (nullable = true)\n",
      " |-- category1Index: double (nullable = false)\n",
      " |-- category1classVec: vector (nullable = true)\n",
      " |-- category2Index: double (nullable = false)\n",
      " |-- category2classVec: vector (nullable = true)\n",
      " |-- binnedhourIndex: double (nullable = false)\n",
      " |-- binnedhourclassVec: vector (nullable = true)\n",
      " |-- brand_newIndex: double (nullable = false)\n",
      " |-- brand_newclassVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of the transformed df\n",
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "|price|day_of_week|  category1|  category2|activity_countval|product_view_counts|category2_view_counts|average_shopping_expense|session_counts|binnedhour|brand_new|is_purchased|day_of_weekIndex|day_of_weekclassVec|category1Index|category1classVec|category2Index|category2classVec|binnedhourIndex|binnedhourclassVec|brand_newIndex|brand_newclassVec|            features|\n",
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "|  540|          6|electronics| smartphone|               35|                  1|                   35|                    null|            35|       3.0|   huawei|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            3.0|     (4,[3],[1.0])|           4.0|   (21,[4],[1.0])|(108,[4,7,20,80,8...|\n",
      "|  114|          5| appliances|environment|                1|                  1|                    1|                    null|             4|       0.0|   others|           0|             2.0|      (7,[2],[1.0])|           1.0|   (13,[1],[1.0])|           7.0|   (57,[7],[1.0])|            2.0|     (4,[2],[1.0])|           0.0|   (21,[0],[1.0])|(108,[2,8,27,79,8...|\n",
      "|   39|          3|electronics|     clocks|                2|                  2|                    2|                    null|             2|       3.0|    casio|           0|             0.0|      (7,[0],[1.0])|           0.0|   (13,[0],[1.0])|           3.0|   (57,[3],[1.0])|            3.0|     (4,[3],[1.0])|          13.0|  (21,[13],[1.0])|(108,[0,7,23,80,9...|\n",
      "|  167|          6|electronics|      audio|                2|                  2|                    2|                    null|            14|       2.0|   others|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[4,7,22,77,8...|\n",
      "|  161|          6|electronics|      audio|               12|                  1|                    1|                    null|           121|       2.0|    apple|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            0.0|     (4,[0],[1.0])|           2.0|   (21,[2],[1.0])|(108,[4,7,22,77,8...|\n",
      "|  437|          4|  computers| components|                4|                  1|                   29|                    null|            85|       2.0|   others|           0|             1.0|      (7,[1],[1.0])|           2.0|   (13,[2],[1.0])|          12.0|  (57,[12],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[1,9,32,77,8...|\n",
      "|   45|          5|    apparel|      shoes|               11|                  2|                   11|                    null|           330|       0.0|   others|           0|             2.0|      (7,[2],[1.0])|           3.0|   (13,[3],[1.0])|           5.0|   (57,[5],[1.0])|            2.0|     (4,[2],[1.0])|           0.0|   (21,[0],[1.0])|(108,[2,10,25,79,...|\n",
      "|  243|          3|electronics| smartphone|                2|                  1|                    2|                    null|             2|       1.0|  samsung|           0|             0.0|      (7,[0],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            1.0|     (4,[1],[1.0])|           1.0|   (21,[1],[1.0])|(108,[0,7,20,78,8...|\n",
      "|  146|          2|electronics|      audio|                3|                  2|                   30|                    null|            74|       1.0|   others|           0|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            1.0|     (4,[1],[1.0])|           0.0|   (21,[0],[1.0])|(108,[6,7,22,78,8...|\n",
      "|  582|          4|electronics| smartphone|                1|                 13|                   50|                    null|           157|       1.0|    apple|           0|             1.0|      (7,[1],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            1.0|     (4,[1],[1.0])|           2.0|   (21,[2],[1.0])|(108,[1,7,20,78,8...|\n",
      "|  250|          6|electronics| smartphone|                2|                  1|                   37|                    null|           118|       2.0|  samsung|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           1.0|   (21,[1],[1.0])|(108,[4,7,20,77,8...|\n",
      "|  131|          4|electronics| smartphone|                3|                  2|                    2|                    null|            33|       2.0|  samsung|           0|             1.0|      (7,[1],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           1.0|   (21,[1],[1.0])|(108,[1,7,20,77,8...|\n",
      "|  179|          2|electronics| smartphone|                4|                  4|                    4|                   192.0|             7|       2.0|     sony|           1|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|          15.0|  (21,[15],[1.0])|(108,[6,7,20,77,9...|\n",
      "|  115|          3| appliances|    kitchen|               37|                  1|                   45|                    null|            50|       2.0|   others|           0|             0.0|      (7,[0],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[0,8,21,77,8...|\n",
      "|  720|          5|  computers|   notebook|               51|                  1|                   63|                    null|           134|       3.0|   lenovo|           0|             2.0|      (7,[2],[1.0])|           2.0|   (13,[2],[1.0])|           4.0|   (57,[4],[1.0])|            3.0|     (4,[3],[1.0])|           8.0|   (21,[8],[1.0])|(108,[2,9,24,80,8...|\n",
      "|   95|          3|       kids|   carriage|                1|                  4|                   18|                    null|            33|       1.0|   others|           0|             0.0|      (7,[0],[1.0])|           7.0|   (13,[7],[1.0])|          16.0|  (57,[16],[1.0])|            1.0|     (4,[1],[1.0])|           0.0|   (21,[0],[1.0])|(108,[0,14,36,78,...|\n",
      "|  197|          7|electronics| smartphone|               13|                  3|                  155|                  228.25|           231|       2.0|   xiaomi|           0|             5.0|      (7,[5],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           3.0|   (21,[3],[1.0])|(108,[5,7,20,77,8...|\n",
      "|  290|          2|electronics| smartphone|               79|                 15|                  840|                    null|           921|       0.0|   xiaomi|           0|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            2.0|     (4,[2],[1.0])|           3.0|   (21,[3],[1.0])|(108,[6,7,20,79,8...|\n",
      "|  405|          6| appliances|    kitchen|               14|                  1|                   17|                    null|           230|       1.0|       lg|           0|             4.0|      (7,[4],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            1.0|     (4,[1],[1.0])|           5.0|   (21,[5],[1.0])|(108,[4,8,21,78,8...|\n",
      "|  100|          1| appliances|    kitchen|               32|                  1|                   52|                    null|            54|       2.0|   others|           0|             3.0|      (7,[3],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[3,8,21,77,8...|\n",
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the elements of the transformed df - Top 20 rows\n",
    "df_clean.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15874983"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "|price|day_of_week|  category1|  category2|activity_countval|product_view_counts|category2_view_counts|average_shopping_expense|session_counts|binnedhour|brand_new|is_purchased|day_of_weekIndex|day_of_weekclassVec|category1Index|category1classVec|category2Index|category2classVec|binnedhourIndex|binnedhourclassVec|brand_newIndex|brand_newclassVec|            features|\n",
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "|  540|          6|electronics| smartphone|               35|                  1|                   35|                    null|            35|       3.0|   huawei|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            3.0|     (4,[3],[1.0])|           4.0|   (21,[4],[1.0])|(108,[4,7,20,80,8...|\n",
      "|  114|          5| appliances|environment|                1|                  1|                    1|                    null|             4|       0.0|   others|           0|             2.0|      (7,[2],[1.0])|           1.0|   (13,[1],[1.0])|           7.0|   (57,[7],[1.0])|            2.0|     (4,[2],[1.0])|           0.0|   (21,[0],[1.0])|(108,[2,8,27,79,8...|\n",
      "|   39|          3|electronics|     clocks|                2|                  2|                    2|                    null|             2|       3.0|    casio|           0|             0.0|      (7,[0],[1.0])|           0.0|   (13,[0],[1.0])|           3.0|   (57,[3],[1.0])|            3.0|     (4,[3],[1.0])|          13.0|  (21,[13],[1.0])|(108,[0,7,23,80,9...|\n",
      "|  167|          6|electronics|      audio|                2|                  2|                    2|                    null|            14|       2.0|   others|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[4,7,22,77,8...|\n",
      "|  161|          6|electronics|      audio|               12|                  1|                    1|                    null|           121|       2.0|    apple|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            0.0|     (4,[0],[1.0])|           2.0|   (21,[2],[1.0])|(108,[4,7,22,77,8...|\n",
      "|  437|          4|  computers| components|                4|                  1|                   29|                    null|            85|       2.0|   others|           0|             1.0|      (7,[1],[1.0])|           2.0|   (13,[2],[1.0])|          12.0|  (57,[12],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[1,9,32,77,8...|\n",
      "|   45|          5|    apparel|      shoes|               11|                  2|                   11|                    null|           330|       0.0|   others|           0|             2.0|      (7,[2],[1.0])|           3.0|   (13,[3],[1.0])|           5.0|   (57,[5],[1.0])|            2.0|     (4,[2],[1.0])|           0.0|   (21,[0],[1.0])|(108,[2,10,25,79,...|\n",
      "|  243|          3|electronics| smartphone|                2|                  1|                    2|                    null|             2|       1.0|  samsung|           0|             0.0|      (7,[0],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            1.0|     (4,[1],[1.0])|           1.0|   (21,[1],[1.0])|(108,[0,7,20,78,8...|\n",
      "|  146|          2|electronics|      audio|                3|                  2|                   30|                    null|            74|       1.0|   others|           0|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           2.0|   (57,[2],[1.0])|            1.0|     (4,[1],[1.0])|           0.0|   (21,[0],[1.0])|(108,[6,7,22,78,8...|\n",
      "|  582|          4|electronics| smartphone|                1|                 13|                   50|                    null|           157|       1.0|    apple|           0|             1.0|      (7,[1],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            1.0|     (4,[1],[1.0])|           2.0|   (21,[2],[1.0])|(108,[1,7,20,78,8...|\n",
      "|  250|          6|electronics| smartphone|                2|                  1|                   37|                    null|           118|       2.0|  samsung|           0|             4.0|      (7,[4],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           1.0|   (21,[1],[1.0])|(108,[4,7,20,77,8...|\n",
      "|  131|          4|electronics| smartphone|                3|                  2|                    2|                    null|            33|       2.0|  samsung|           0|             1.0|      (7,[1],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           1.0|   (21,[1],[1.0])|(108,[1,7,20,77,8...|\n",
      "|  179|          2|electronics| smartphone|                4|                  4|                    4|                   192.0|             7|       2.0|     sony|           1|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|          15.0|  (21,[15],[1.0])|(108,[6,7,20,77,9...|\n",
      "|  115|          3| appliances|    kitchen|               37|                  1|                   45|                    null|            50|       2.0|   others|           0|             0.0|      (7,[0],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[0,8,21,77,8...|\n",
      "|  720|          5|  computers|   notebook|               51|                  1|                   63|                    null|           134|       3.0|   lenovo|           0|             2.0|      (7,[2],[1.0])|           2.0|   (13,[2],[1.0])|           4.0|   (57,[4],[1.0])|            3.0|     (4,[3],[1.0])|           8.0|   (21,[8],[1.0])|(108,[2,9,24,80,8...|\n",
      "|   95|          3|       kids|   carriage|                1|                  4|                   18|                    null|            33|       1.0|   others|           0|             0.0|      (7,[0],[1.0])|           7.0|   (13,[7],[1.0])|          16.0|  (57,[16],[1.0])|            1.0|     (4,[1],[1.0])|           0.0|   (21,[0],[1.0])|(108,[0,14,36,78,...|\n",
      "|  197|          7|electronics| smartphone|               13|                  3|                  155|                  228.25|           231|       2.0|   xiaomi|           0|             5.0|      (7,[5],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            0.0|     (4,[0],[1.0])|           3.0|   (21,[3],[1.0])|(108,[5,7,20,77,8...|\n",
      "|  290|          2|electronics| smartphone|               79|                 15|                  840|                    null|           921|       0.0|   xiaomi|           0|             6.0|      (7,[6],[1.0])|           0.0|   (13,[0],[1.0])|           0.0|   (57,[0],[1.0])|            2.0|     (4,[2],[1.0])|           3.0|   (21,[3],[1.0])|(108,[6,7,20,79,8...|\n",
      "|  405|          6| appliances|    kitchen|               14|                  1|                   17|                    null|           230|       1.0|       lg|           0|             4.0|      (7,[4],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            1.0|     (4,[1],[1.0])|           5.0|   (21,[5],[1.0])|(108,[4,8,21,78,8...|\n",
      "|  100|          1| appliances|    kitchen|               32|                  1|                   52|                    null|            54|       2.0|   others|           0|             3.0|      (7,[3],[1.0])|           1.0|   (13,[1],[1.0])|           1.0|   (57,[1],[1.0])|            0.0|     (4,[0],[1.0])|           0.0|   (21,[0],[1.0])|(108,[3,8,21,77,8...|\n",
      "+-----+-----------+-----------+-----------+-----------------+-------------------+---------------------+------------------------+--------------+----------+---------+------------+----------------+-------------------+--------------+-----------------+--------------+-----------------+---------------+------------------+--------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the elements of the transformed df - Top 20 rows\n",
    "df_clean.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test (Remember you are expected to compare the model later)\n",
    "traindata, testdata = df_clean.randomSplit([0.7,0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11113821"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in train and test data\n",
    "traindata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4761162"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model with hyperparameter tuning\n",
    "# Create ParamGrid for Cross Validation\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"is_purchased\", featuresCol=\"features\")\n",
    "\n",
    "dt_model = dt.fit(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CrossValidator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-372e3108504c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Run cross-validation, and choose the best set of parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcrossval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mcrossval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CrossValidator' object is not callable"
     ]
    }
   ],
   "source": [
    "# Run cross-validation steps\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [2,3,5]) \\\n",
    "    .addGrid(dt.minInstancesPerNode, [5,10,20]) \\\n",
    "    .addGrid(dt.impurity, ['entropy', 'gini']) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=dt_model,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5)  # use 3+ folds in practice\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "crossval = crossval(maxIter=10)\n",
    "crossval = crossval.fit(traindata)\n",
    "cvModel = crossval.fit(traindata)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction = cvModel.transform(testdata)\n",
    "selected = prediction.select(\"is_purchased\", \"probability\", \"prediction\")\n",
    "for row in selected.collect():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the models on transformed df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model from the results of cross-validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Steps:\n",
    "- Fit on test data\n",
    "- Performance analysis\n",
    "    - Appropriate Metric with reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the model on test set\n",
    "predictions = dt_model.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----------+--------------------+\n",
      "|is_purchased|       rawPrediction|prediction|         probability|\n",
      "+------------+--------------------+----------+--------------------+\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "|           0|[1.0769307E7,3445...|       0.0|[0.96900130027287...|\n",
      "+------------+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the required columns\n",
    "predictions.select('is_purchased', 'rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(108, {})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Importance\n",
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to extract features along with the feature importance score\n",
    "import pandas as pd\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>price</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>62</td>\n",
       "      <td>category2classVec_lawn_mower</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>73</td>\n",
       "      <td>category2classVec_skirt</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>72</td>\n",
       "      <td>category2classVec_tennis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>71</td>\n",
       "      <td>category2classVec_furniture</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>70</td>\n",
       "      <td>category2classVec_sock</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>69</td>\n",
       "      <td>category2classVec_jumper</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>68</td>\n",
       "      <td>category2classVec_jeans</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>67</td>\n",
       "      <td>category2classVec_scarf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>66</td>\n",
       "      <td>category2classVec_ski</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                          name  score\n",
       "0   102                         price    0.0\n",
       "68   62  category2classVec_lawn_mower    0.0\n",
       "79   73       category2classVec_skirt    0.0\n",
       "78   72      category2classVec_tennis    0.0\n",
       "77   71   category2classVec_furniture    0.0\n",
       "76   70        category2classVec_sock    0.0\n",
       "75   69      category2classVec_jumper    0.0\n",
       "74   68       category2classVec_jeans    0.0\n",
       "73   67       category2classVec_scarf    0.0\n",
       "72   66         category2classVec_ski    0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the feature importance scores\n",
    "ExtractFeatureImp(dt_model.featureImportances, predictions, \"features\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_purchased\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688395395913855"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries required to print the confusion matrix\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Place the predictions and labels together\n",
    "preds_and_labels = predictions.select(['prediction','is_purchased']).withColumn('label', F.col('is_purchased').cast(FloatType())).orderBy('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_labels = preds_and_labels.select(['prediction','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4612802.       0.]\n",
      " [ 148360.       0.]]\n"
     ]
    }
   ],
   "source": [
    "#convert into RDD\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "#print in form of an array\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688395395913855"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate recall\n",
    "recall = metrics.recall()\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688395395913855"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate precision\n",
    "precision = metrics.precision()\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the best Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy, REcall and Precision are @ 96.88%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
